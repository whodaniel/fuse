# The New Fuse: Agent-to-Agent Communication Guide (Updated)

## Overview
This document is a comprehensive guide to the agent-to-agent (A2A) communication system in The New Fuse project. It consolidates all findings, best practices, message formats, infrastructure details, and recommendations for further improvement. This updated version incorporates insights and refinements based on implementation experience, particularly concerning reliable messaging with Redis Streams and coordinating multiple distributed agents within environments like VS Code extensions. All agents and contributors are encouraged to continue updating this guide as new insights, improvements, or proven results are discovered.

---

## 1. Communication Protocols & Message Formats

Messages exchanged between agents form the backbone of collaboration. Standardized protocols and formats are essential for ensuring interoperability, traceability, and reliable processing.

### 1.1 Standard Message Structure
Messages exchanged between agents should follow a structured format, typically JSON. Example from `agent_communication.json`:

```json
{
    "type": "COLLABORATION_REQUEST",
    "source": "TNF_AG_001",
    "target": "cascade_agent",
    "content": {
        "action": "task_assistance",
        "task_type": "code_review",
        "context": {
            "file": "packages/core/src/services/agent/agent.service.ts",
            "focus_areas": ["error_handling", "memory_management"]
        },
        "priority": "medium"
    },
    "timestamp": "2024-01-06T10:02:00Z"
}
Key Fields
type: The primary purpose or category of the message (e.g., COLLABORATION_REQUEST, TASK_UPDATE, EVENT_NOTIFICATION). This is crucial for consumers to quickly determine if they need to process the message.
source: The unique identifier of the sending agent.
target: The unique identifier of the intended recipient agent. Messages can be addressed to a specific agent ID, a group ID, or a broadcast channel.
content: A structured payload containing the details of the message's purpose. The structure within content is specific to the type of message.
timestamp: An ISO8601 formatted string indicating when the message was created. Essential for ordering and debugging.
message_id: (Implicit or Explicit) A unique identifier for the message instance, typically generated by the messaging system (like Redis Streams' message ID) or explicitly included for end-to-end traceability.
metadata: (Optional) Additional key-value pairs providing context, such as priority, related task IDs, protocol version, or flags for processing.
1.2 Agent Registration
Agents joining the network must register their presence and basic information. This allows other agents and coordination services to discover them. Agents register using a payload like agent_registration.json:

JSON

{
    "type": "REGISTRATION",
    "entity_type": "ai_agent",
    "credentials": {
        "username": "augment_ai",
        "authentication_method": "jwt", // Or 'signature', 'api_key', etc.
        "agent_signature": "sha256_hash_of_augment_identity_or_certificate" // For verification
    },
    "profile": {
        "name": "Augment", // Human-readable name
        "type": "autonomous_agent", // e.g., 'autonomous_agent', 'user_proxy', 'coordinator'
        "origin": "augment_code", // Source project or location
        "primary_function": "code_assistant",
        "capabilities": [ // List of capabilities declared by the agent
            "code_analysis",
            "software_engineering",
            "system_integration",
            "documentation"
        ],
        "version": "1.5" // Agent's software version
    },
    "timestamp": "2024-04-27T14:25:00Z"
}
1.3 Capability Declaration & Assessment
For effective collaboration, agents need to know what tasks other agents are capable of performing and assess their proficiency.

Capability Declaration
Agents should proactively declare their capabilities upon registration or whenever their abilities change.

JSON

{
    "type": "CAPABILITY_DECLARATION",
    "source": "agent_alpha",
    "capabilities": [
        {
            "id": "code_generation", // Unique capability identifier
            "version": "2.1", // Version of this specific capability implementation
            "description": "Generate code in multiple languages based on requirements",
            "languages": ["JavaScript", "Python", "TypeScript", "Go"],
            "confidence": 0.95 // Agent's self-assessed confidence level (0.0 to 1.0)
        },
        {
            "id": "system_design",
            "version": "1.3",
            "description": "Create system architecture diagrams and specifications",
            "confidence": 0.87
        }
    ],
    "timestamp": "2024-04-27T14:30:00Z"
}
Capability Assessment Request
Agents can request an assessment of another agent's capabilities, potentially from a trusted third party or the agent itself if it supports self-assessment endpoints.

JSON

{
    "type": "CAPABILITY_ASSESSMENT_REQUEST",
    "source": "agent_beta",
    "target": "agent_alpha", // Agent to be assessed, or 'central_registry'
    "requested_capabilities": ["code_generation", "system_design"],
    "context": { // Provide context relevant to the assessment
        "project": "The New Fuse Extension",
        "requirements": ["TypeScript compatibility", "VSCode integration"]
    },
    "timestamp": "2024-04-27T14:35:00Z"
}
2. Communication Infrastructure
The communication infrastructure facilitates message exchange between agents. Reliability and scalability are key considerations.

2.1 Redis-Based Messaging (Streams for Reliability)
Redis is the primary backbone for reliable asynchronous messaging between agents. We primarily leverage Redis Streams for guaranteed delivery, message history, and consumer groups, which are essential for distributing tasks among multiple instances of the same agent type (e.g., multiple VS Code extensions acting as worker agents).

Primary Streams: Agents will consume and produce messages on designated streams. Common patterns include:

tasks:<task_type>: Streams dedicated to specific types of tasks (e.g., tasks:code_review, tasks:refactor). Agents specializing in a task type consume from its stream.
events:<event_type>: Streams for broadcasting significant events (e.g., events:file_changed, events:agent_status).
agent:<agent_id>:inbox: Streams for direct, reliable messages to a specific agent instance or ID.
agents:<group_id>:broadcast: Streams for messages intended for a specific group of agents.
Pub/Sub vs. Streams: While Redis Pub/Sub exists (SUBSCRIBE, PUBLISH), it offers a fire-and-forget model. Messages are not persisted, and consumers must be connected at the time of publication. Redis Streams (XADD, XREADGROUP, XACK, XAUTOCLAIM) are preferred for core A2A communication because they provide:

Persistence: Messages are stored.
Guaranteed Delivery: Messages are tracked per consumer group.
Consumer Groups: Multiple consumers can safely process the same stream without duplicating messages, enabling load balancing and failover.
History: Consumers can access past messages.
Connection Steps (using @redis/client):

Initialize the Redis client (configured for a single instance, Sentinel, or Cluster as needed - see redisClient.ts).
Ensure the necessary consumer groups exist for the streams the agent will consume from (XGROUP CREATE). This is idempotent and safe to run on startup.
Start a consumer loop that uses XREADGROUP to read messages assigned to the agent instance within its group. Use BLOCK for efficiency.
Process the received message.
Acknowledge the message using XACK upon successful processing.
Implement logic (often using XAUTOCLAIM) to handle messages that were assigned to a consumer in the group but never acknowledged (indicating a potential crash).
TypeScript

// Example using XREADGROUP within a consumer loop
// See detailed consumer.ts example in Section 3.1

// Inside your agent's main processing loop:
const messages = await client.xReadGroup(groupName, consumerName, {
    key: streamName,
    id: '>', // Read new messages not yet delivered to *any* consumer in this group
}, {
    count: 1, // Process one message at a time
    block: 5000, // Block for 5 seconds if no messages
});

if (messages && messages.length > 0) {
    for (const streamResult of messages) {
         for (const message of streamResult.messages) {
             try {
                 // message.id is the Stream message ID
                 // message.message contains the key-value pairs (e.g., { taskJson: '...' })
                 await processStreamMessage(message.id, message.message);
             } catch (processingError) {
                 console.error(`Failed to process message ${message.id}:`, processingError);
                 // Error handled and message acknowledged/DLQ'd within processStreamMessage
             }
         }
    }
} else {
    // No new messages, check for pending messages from crashed consumers
    // Use XAUTOCLAIM here (see Section 4.3 A2ACoordinator details)
}
Publish messages (tasks, events, direct communication) to relevant streams using XADD.
TypeScript

// Example using XADD
// See detailed producer.ts example in Section 3.1

// To send a message/task:
const messageId = await client.xAdd('tasks:code_review', '*', {
    taskJson: JSON.stringify({ /* task details */ }),
    source: agentId,
    target: 'code_reviewer_group', // Target can be used by consumers to filter
    type: 'TASK_REQUEST',
    // ... other fields from Standard Message Structure
});
console.log(`Published message ${messageId} to stream`);
2.2 MCP Server (Optional, but Recommended)
Role: Acts as a registry and potential routing layer for agents offering capabilities via the Model Context Protocol. It helps agents discover and invoke tools provided by other agents without needing direct P2P connections or hardcoding endpoints.
Location: ./src/mcp/SimpleMCPServer.js (or a dedicated service)
Default Port: 3000
Endpoints:
Health: http://localhost:3000/health
API: http://localhost:3000/api/agents (for registration/discovery)
MCP Endpoint: http://localhost:3000/mcp (for tool invocation)
Startup: Use quick-start-mcp.sh or VS Code tasks to initialize. Agents would register their MCP tools with this server.
2.3 Docker & Deployment
Multiple Dockerfiles and compose files support containerized deployment of agents and infrastructure services (Redis, MCP Server).
See docker-compose.*.yml and Dockerfile.* for details on setting up the environment for scalable agent deployment.
3. Implementation Patterns (Core Redis)
These patterns demonstrate fundamental Redis interactions using @redis/client that form the building blocks for agent functionality.

3.1 Redis Streams (Producer/Consumer Examples)
These examples, implemented in TypeScript, show how agents interact with Redis Streams for task distribution.

producer.ts: (See Section 1.1 for CodeTask interface)

TypeScript

import { getRedisClient } from './redisClient';

const streamName = 'agent_tasks'; // Consistent stream name

interface AgentTaskMessage {
    type: 'TASK_REQUEST';
    taskId: string; // Unique ID for the task
    source: string; // Agent initiating the task
    target: string; // Intended recipient (agent ID or group ID)
    payload: any; // Task-specific data
    timestamp: string;
    // ... other standard message fields like metadata, message_id (handled by Redis)
}

async function addTaskToQueue(taskMessage: Omit<AgentTaskMessage, 'timestamp'>): Promise<string | undefined> {
    const client = await getRedisClient();
    const messagePayload = {
         ...taskMessage,
         timestamp: new Date().toISOString(),
         payload: JSON.stringify(taskMessage.payload), // Stringify payload for storage
    };
    try {
        // XADD command: Add a message to the stream
        const messageId = await client.xAdd(streamName, '*', messagePayload);
        console.log(`[Producer] Added task ${taskMessage.taskId} with message ID: ${messageId}`);
        return messageId;
    } catch (error) {
        console.error(`[Producer] Failed to add task ${taskMessage.taskId} to stream:`, error);
        throw error; // Re-throw error
    }
}

// Example usage (would be called by a part of an agent or UI):
/*
async function createAndEnqueueTask() {
    const taskId = `task-${Date.now()}-${Math.random().toString(36).substring(7)}`; // Simple unique ID
    const taskDetails = {
        type: 'refactor',
        filePath: 'src/utils.ts',
        description: 'Refactor utility functions for clarity',
        focus_areas: ['readability', 'performance']
    };
    const taskMessage: Omit<AgentTaskMessage, 'timestamp'> = {
        type: 'TASK_REQUEST',
        taskId: taskId,
        source: 'user_proxy_agent', // Or the agent creating the task
        target: 'code_agent_group', // Target a group of code agents
        payload: taskDetails
    };
    try {
        await addTaskToQueue(taskMessage);
         console.log(`Task ${taskId} enqueued.`);
    } catch (e) {
         console.error(`Failed to enqueue task ${taskId}:`, e);
    }
}
// createAndEnqueueTask(); // Call this to add a task
*/
consumer.ts:

TypeScript

import { getRedisClient } from './redisClient';
import { XReadGroupResponse } from '@redis/client';

const taskStream = 'agent_tasks'; // Consistent stream name
const consumerGroupName = 'code_agents_group'; // Group for agents processing these tasks
const consumerName = `agent_instance_${process.pid}_${Date.now()}`; // Unique ID for this consumer instance

async function ensureConsumerGroupExists() {
    const client = await getRedisClient();
    try {
        // XGROUP CREATE command: Create a consumer group
        await client.xGroupCreate(taskStream, consumerGroupName, '0', { MKSTREAM: true });
        console.log(`[Consumer ${consumerName}] Consumer group '${consumerGroupName}' created or already exists.`);
    } catch (error: any) {
        if (error.message && error.message.includes('BUSYGROUP')) {
            console.log(`[Consumer ${consumerName}] Consumer group '${consumerGroupName}' already exists.`);
        } else {
            console.error(`[Consumer ${consumerName}] Error creating consumer group:`, error);
            throw error;
        }
    }
}

async function processStreamMessage(messageId: string, messageData: { [key: string]: string }) {
    const client = await getRedisClient();
    const taskMessageString = messageData['payload']; // Assuming 'payload' field holds the task JSON
    const originalMessageProps = { // Capture other standard fields
        type: messageData['type'],
        taskId: messageData['taskId'],
        source: messageData['source'],
        target: messageData['target'],
        timestamp: messageData['timestamp'],
    };


    if (!taskMessageString) {
        console.warn(`[Consumer ${consumerName}] Message ${messageId} missing 'payload'. Acknowledging.`);
        await client.xAck(taskStream, consumerGroupName, messageId);
        return;
    }

    let taskPayload: any;
    try {
        taskPayload = JSON.parse(taskMessageString);
        console.log(`[Consumer ${consumerName}] Received task ${originalMessageProps.taskId} (Msg ID: ${messageId}) Type: ${originalMessageProps.type}`);

        // --- Agent Task Processing Logic ---
        // This is where your agent's core logic for a specific task type runs.
        // Example: If type is 'TASK_REQUEST' and payload.type is 'code_review'
        // You would perform the code review based on taskPayload.
        // This might involve acquiring locks, using RediSearch, interacting with VS Code APIs, etc.
        // See Section 4 for coordination aspects.

        console.log(`[Consumer ${consumerName}] Processing task payload for ${originalMessageProps.taskId}:`, taskPayload);
        await new Promise(resolve => setTimeout(resolve, 1500)); // Simulate work

        console.log(`[Consumer ${consumerName}] Finished processing task ${originalMessageProps.taskId}.`);

        // --- End Agent Task Processing Logic ---

        // XACK command: Acknowledge the message upon successful processing
        await client.xAck(taskStream, consumerGroupName, messageId);
        console.log(`[Consumer ${consumerName}] Acknowledged task ${originalMessageProps.taskId} (Msg ID: ${messageId}).`);

    } catch (error: any) {
        console.error(`[Consumer ${consumerName}] Error processing message ${messageId} (Task ${originalMessageProps.taskId}):`, error);
        // --- Robust Error Handling ---
        // 1. Log the error.
        // 2. Mark the task as failed or needing retry in a task registry (See Section 4.1).
        // 3. Potentially move the message to a Dead Letter Queue (DLQ) stream
        //    This prevents a constantly failing message from blocking the consumer group.
        //    Example: Add to a DLQ stream and then acknowledge from the main stream.
        // await client.xAdd(`${taskStream}:dlq`, '*', { originalMessageId: messageId, error: error.message, ...messageData });
        // await client.xAck(taskStream, consumerGroupName, messageId); // Acknowledge from main stream after moving to DLQ
        // --- End Error Handling ---

         // For this basic example, just log and acknowledge to prevent getting stuck
         await client.xAck(taskStream, consumerGroupName, messageId); // Acknowledge even on failure for simple setup
         console.log(`[Consumer ${consumerName}] Acknowledged message ${messageId} after error.`);
    }
}

async function startTaskConsumer() {
    try {
        await ensureConsumerGroupExists();
    } catch (e) {
        console.error(`[Consumer ${consumerName}] Failed to ensure consumer group exists, exiting.`, e);
        process.exit(1);
    }

    const client = await getRedisClient();
    console.log(`[Consumer ${consumerName}] Starting consumer in group ${consumerGroupName} on stream '${taskStream}'...`);

    while (true) {
        try {
            // XREADGROUP command: Read messages for this consumer instance in the group
            const messages: XReadGroupResponse | null = await client.xReadGroup(consumerGroupName, consumerName, {
                key: taskStream,
                id: '>', // Read new messages not yet delivered to *any* consumer in this group
            }, {
                count: 1, // Process one message at a time
                block: 5000, // Block for 5 seconds if no messages are available
            });

            if (messages && messages.length > 0) {
                for (const streamResult of messages) {
                     for (const message of streamResult.messages) {
                         // Process the message (includes ACK or DLQ logic)
                         await processStreamMessage(message.id, message.message);
                     }
                }
            } else {
                // No new messages, check for pending messages from crashed consumers
                // Use XAUTOCLAIM here (see Section 4.3 A2ACoordinator details for example)
                 console.log(`[Consumer ${consumerName}] No new messages. Checking for pending...`);
                 // await claimPendingMessages(); // Call a function implementing XAUTOCLAIM
            }

        } catch (error) {
            console.error(`[Consumer ${consumerName}] An error occurred during consumption loop:`, error);
            // Wait before retrying the read loop to avoid tight loop on connection errors
            await new Promise(resolve => setTimeout(resolve, 5000));
        }
    }
}

// startTaskConsumer().catch(console.error); // Call this function to start the consumer in an agent instance
3.2. Redis Stack (RediSearch/Vector Sets) for Vector Database
Creating an index, adding documents with vectors, and performing vector similarity search. Requires @redis/search. Essential for RAG over codebases or other knowledge sources.

vectorDbExample.ts:

TypeScript

import { getRedisClient } from './redisClient'; // Use the extended client type
import {
    SchemaFieldTypes,
    VectorAlgorithms,
    SearchReply,
} from '@redis/search';

const indexName = "my_vector_index";
const prefix = "doc:"; // Key prefix for documents indexed
const vectorDimensions = 3; // Example dimension, replace with your actual vector size
const vectorDistanceMetric = 'COSINE'; // COSINE, L2, IP - must match your vector space

async function createVectorIndex() {
    const client = await getRedisClient(); // Use the extended client

    try {
        // FT.CREATE command: Define and create the search index
        const schema = {
            content: { type: SchemaFieldTypes.TEXT }, // Text field for full-text search
            tag: { type: SchemaFieldTypes.TAG }, // Tag field for filtering/faceting
            vector: { // Vector field for similarity search
                type: SchemaFieldTypes.VECTOR,
                AS: 'vector', // Alias for the field in results
                ALGORITHM: VectorAlgorithms.FLAT, // Or HNSW for larger datasets/better recall
                ATTRIBUTES: {
                    TYPE: 'FLOAT32', // FLOAT32 (standard) or FLOAT64
                    DIM: vectorDimensions,
                    DISTANCE_METRIC: vectorDistanceMetric,
                },
            } as const, // Use 'as const' for strong typing
        };

        await client.ft(indexName).create(schema, {
             ON: 'HASH', // Index Redis Hash keys
             PREFIX: prefix, // Only index keys starting with this prefix
             // STOPWORDS: [], // Optional: custom stopwords
             // Other options like noOffsets, noFreqs for optimization
        });
        console.log(`[Vector DB] Index '${indexName}' created.`);
    } catch (error: any) {
        if (error.message && error.message.includes('Index already exists')) {
            console.log(`[Vector DB] Index '${indexName}' already exists.`);
        } else {
            console.error('[Vector DB] Error creating index:', error);
            throw error;
        }
    }
}

async function addDocumentWithVector(docId: string, content: string, tag: string, vector: Float32Array) {
    const client = await getRedisClient();
    const key = `${prefix}${docId}`; // Use the defined prefix
    try {
        // HSET command: Store data and vector in a Redis Hash
        await client.hSet(key, {
            content: content,
            tag: tag,
            // Store vector as a Buffer (Node.js equivalent of bytes). Must be Float32Array or Float64Array.
            vector: Buffer.from(vector.buffer),
        });
        console.log(`[Vector DB] Added document: ${key}`);
    } catch (error) {
        console.error(`[Vector DB] Error adding document ${key}:`, error);
        throw error;
    }
}

async function searchByVectorSimilarity(queryVector: Float32Array, k: number = 2): Promise<any[]> {
    const client = await getRedisClient();
    try {
        // Convert query vector to Buffer
        const queryVectorBuffer = Buffer.from(queryVector.buffer);

        // FT.SEARCH command with KNN vector query
        // `*` matches all documents (can add text/tag filters here, e.g., `@tag:{AI}`)
        // `[KNN k @vector $vec_param AS vector_score]` performs K-Nearest Neighbors search
        // `PARAMS { vec_param: ... }` passes the query vector as a named parameter
        // `RETURN` specifies fields to return (include vector_score alias)
        // `SORTBY` sorts results by the vector score (ascending for distance, descending for similarity)
        // `DIALECT 2` enables modern query syntax

        const query = `*=>[KNN ${k} @vector $vec_param AS vector_score]`;
        // Example hybrid query: `@tag:{AI | ML}=>[KNN ${k} @vector $vec_param AS vector_score]`

        const results: SearchReply = await client.ft(indexName).search(query, {
            QUERY: {
                PARAMS: {
                    vec_param: queryVectorBuffer
                },
                RETURN: ['content', 'tag', 'vector_score'],
                // Sort by vector_score. @redis/search sorts ascending by default for numbers.
                // For similarity metrics (COSINE, IP), a higher score is better, so sort descending.
                // For distance metrics (L2), a lower score is better, so sort ascending (default).
                // If using COSINE/IP, you might need to manually reverse results or check client capabilities for descending sort on aliases.
                // A common pattern is to negate the distance/similarity in the query or client.
                // RediSearch's SORTBY command on an alias often sorts numerically.
                // If vector_score is similarity (0 to 1), higher is better, need DESC sort.
                // If vector_score is distance (0 to Inf), lower is better, need ASC sort.
                // Let's assume vector_score is similarity for COSINE, so we sort DESC.
                // The `@redis/search` client's `SORTBY` might require the actual field name or alias depending on version/implementation.
                // Using the alias 'vector_score' here. Check your client version docs.
                // For simplicity, assume default sort is ok or handle sorting client-side if needed.
                // Let's assume the client handles sorting direction appropriately for the metric.
                // A more explicit sort might be: SORTBY 'vector_score' DESC
                SORTBY: 'vector_score', // Client might default ASC, manual sort or negation might be needed for DESC
                DIALECT: 2,
            }
        });

        console.log(`\n[Vector DB] Search Results (Top ${k}):`);
        const documents = results.documents || [];
        // If COSINE/IP, sort client-side descending if SORTBY 'vector_score' in query defaults to ASC
        if (vectorDistanceMetric === 'COSINE' || vectorDistanceMetric === 'IP') {
            documents.sort((a: any, b: any) => parseFloat(b.value.vector_score) - parseFloat(a.value.vector_score));
        }


        documents.forEach((doc: any, i: number) => { // Doc structure requires careful type handling
            const score = parseFloat(doc.value.vector_score);
             console.log(`${i+1}. ID: ${doc.id}, Content: "${doc.value.content.substring(0, 50)}...", Tag: ${doc.value.tag}, Score: ${score.toFixed(4)}`);
        });
        return documents.map(doc => doc.value);
    } catch (error) {
        console.error('[Vector DB] Error during vector search:', error);
        throw error;
    }
}

async function runVectorDbExample() {
    await createVectorIndex();

    // Example vectors (replace with real embeddings from an embedding model)
    // Using Float32Array as it aligns with Redis FLOAT32 type
    const vec1 = new Float32Array([0.1, 0.2, 0.3]);
    const vec2 = new Float32Array([0.9, 0.8, 0.7]);
    const vec3 = new Float32Array([0.2, 0.3, 0.1]);
    const vec4 = new Float32Array([0.5, 0.5, 0.5]);

    await addDocumentWithVector('1', "This is the first document about artificial intelligence.", "AI", vec1);
    await addDocumentWithVector('2', "The second document discusses machine learning algorithms.", "ML", vec2);
    await addDocumentWithVector('3', "Another document related to AI and neural networks.", "AI", vec3);
    await addDocumentWithVector('4', "A general document about data science.", "DataScience", vec4);

    // Example query vector (e.g., embedding of "Tell me about AI")
    const queryVec = new Float32Array([0.15, 0.25, 0.35]);

    await searchByVectorSimilarity(queryVec, 3);

    // Example of a hybrid text and vector search (more complex query)
    // const hybridQuery = `@tag:{AI | ML}=>[KNN 2 @vector $vec_param AS vector_score]`;
    // const queryVectorBuffer = Buffer.from(queryVec.buffer);
    // const hybridResults: SearchReply = await client.ft(indexName).search(hybridQuery, {
    //     QUERY: {
    //         PARAMS: { vec_param: queryVectorBuffer },
    //         RETURN: ['content', 'tag', 'vector_score'],
    //         SORTBY: vectorDistanceMetric === 'L2' ? 'vector_score' : '@vector_score',
    //         DIALECT: 2
    //     }
    // });
    // console.log("\n[Vector DB] Hybrid Search Results (AI or ML tag + Vector):", hybridResults.documents);

    // In a real app, keep client connected
    // await (await getRedisClient()).quit();
}

// runVectorDbExample().catch(console.error); // Call this function when needed
3.3. LLM Memory Management
Using Redis Hashes to store conversational history per session. Useful for maintaining state in a chatbot-like interaction within an agent.

llmMemoryExample.ts:

TypeScript

import { getRedisClient } from './redisClient';

interface ChatMessage {
    role: 'user' | 'assistant';
    content: string;
    timestamp?: number; // Optional: for ordering
}

async function getConversationMemory(sessionId: string): Promise<ChatMessage[]> {
    const client = await getRedisClient();
    const memoryKey = `conversation:${sessionId}`;
    try {
        // HGETALL command: Get all fields (messages) from the Hash
        const messagesMap = await client.hGetAll(memoryKey);
        if (!messagesMap || Object.keys(messagesMap).length === 0) {
            return [];
        }

        const conversation: ChatMessage[] = [];
        // Get keys and sort them assuming sequential naming like 'msg_0', 'msg_1'
        // A more robust approach uses the timestamp within the message payload for sorting if keys are not guaranteed sequential.
        const sortedKeys = Object.keys(messagesMap).sort((a, b) => {
            const numA = parseInt(a.split('_')[1], 10); // Ensure base 10
            const numB = parseInt(b.split('_')[1], 10);
            return numA - numB;
        });


        for (const key of sortedKeys) {
            try {
                const messageDataString = messagesMap[key];
                if (messageDataString) {
                     const messageData: ChatMessage = JSON.parse(messageDataString);
                     conversation.push(messageData);
                }
            } catch (error) {
                console.warn(`[Memory] Could not parse message for key ${key}:`, error);
                continue; // Skip malformed messages
            }
        }
        return conversation;

    } catch (error) {
        console.error(`[Memory] Error getting conversation memory for session ${sessionId}:`, error);
        throw error;
    }
}

async function addMessageToMemory(sessionId: string, role: 'user' | 'assistant', content: string) {
    const client = await getRedisClient();
    const memoryKey = `conversation:${sessionId}`;
    try {
        // HLEN command: Get the current number of messages to use as a field index
        const messageCount = await client.hLen(memoryKey);
        const fieldName = `msg_${messageCount}`; // Simple sequential key

        const messageData: ChatMessage = { role, content, timestamp: Date.now() };

        // HSET command: Store the message as a field in the Hash
        await client.hSet(memoryKey, fieldName, JSON.stringify(messageData));
        console.log(`[Memory] Added message to session ${sessionId}`);

    } catch (error) {
        console.error(`[Memory] Error adding message to session ${sessionId}:`, error);
        throw error;
    }
}

async function clearConversationMemory(sessionId: string) {
    const client = await getRedisClient();
    const memoryKey = `conversation:${sessionId}`;
    try {
        // DEL command: Delete the entire Hash (conversation)
        await client.del(memoryKey);
        console.log(`[Memory] Cleared conversation memory for session ${sessionId}`);
    } catch (error) {
        console.error(`[Memory] Error clearing memory for session ${sessionId}:`, error);
        throw error;
    }
}

async function runMemoryExample() {
    const sessionId = "user123";

    // Simulate a conversation
    await addMessageToMemory(sessionId, "user", "Hi there!");
    await addMessageToMemory(sessionId, "assistant", "Hello! How can I help you today?");
    await addMessageToMemory(sessionId, "user", "Tell me about Redis.");

    // Retrieve the conversation
    const conversation = await getConversationMemory(sessionId);
    console.log("\n[Memory] Conversation History:");
    conversation.forEach(msg => console.log(`- ${msg.role}: ${msg.content}`));

    // Simulate another turn
    await addMessageToMemory(sessionId, "assistant", "Redis is an open-source in-memory data structure store.");

    const updatedConversation = await getConversationMemory(sessionId);
    console.log("\n[Memory] Updated Conversation History:");
    updatedConversation.forEach(msg => console.log(`- ${msg.role}: ${msg.content}`));

    // Clear the memory
    // await clearConversationMemory(sessionId);
    // console.log("\n[Memory] After clearing:");
    // console.log(await getConversationMemory(sessionId));

    // In a real app, keep client connected
    // await (await getRedisClient()).quit();
}

// runMemoryExample().catch(console.error); // Call this function when needed
3.4. Caching Strategies
Simple cache lookup using Redis Strings with expiration. Crucial for optimizing repeated computations or data fetches.

cachingExample.ts:

TypeScript

import { getRedisClient } from './redisClient';

async function getDataFromCacheOrSource(key: string): Promise<string | null> {
    const client = await getRedisClient();
    const cacheKey = `cache:${key}`;
    const cacheExpirationSeconds = 60; // Cache for 60 seconds

    try {
        // GET command: Try to get from cache
        const cachedData = await client.get(cacheKey);

        if (cachedData !== null) {
            console.log(`[Cache] Cache hit for key: ${key}`);
            return cachedData; // Data is already a string
        } else {
            console.log(`[Cache] Cache miss for key: ${key}. Fetching from source...`);
            // Simulate fetching data from a slow source
            const data = await fetchDataFromSource(key);

            // SET command with EX option: Cache the data with an expiration time
            if (data !== null) {
                await client.set(cacheKey, data, {
                    EX: cacheExpirationSeconds, // Set expiration in seconds
                });
                console.log(`[Cache] Data for key '${key}' cached with expiration.`);
            }
            return data;
        }

    } catch (error) {
        console.error(`[Cache] Error during caching operation for key ${key}:`, error);
        // Fallback to fetching directly if cache operation fails
        try {
            console.warn(`[Cache] Attempting direct fetch due to cache error for key: ${key}`);
            return fetchDataFromSource(key);
        } catch (fallbackError) {
             console.error(`[Cache] Error during fallback fetch for key ${key}:`, fallbackError);
             return null; // Return null if fallback also fails
        }
    }
}

async function fetchDataFromSource(key: string): Promise<string | null> {
    """Simulates fetching data from an external source (slow)."""
    console.log(`[Cache] Fetching data for '${key}' from source...`);
    await new Promise(resolve => setTimeout(resolve, 2000)); // Simulate delay
    // Simulate potential failure
    if (Math.random() < 0.1) { // 10% chance of simulated failure
         console.error(`[Cache] Simulated failure fetching data for ${key}`);
         // throw new Error("Simulated fetch error"); // Re-throw if you want to handle outside
         return null; // Or return null/undefined on simulated failure
    }
    return `Data for ${key} from source at ${new Date().toISOString()}`; // Return some data
}


async function runCachingExample() {
    const dataKey = "report:daily_summary";

    // First call (cache miss)
    const result1 = await getDataFromCacheOrSource(dataKey);
    console.log(`[Cache] Result 1: ${result1}\n`);

    // Second call immediately (cache hit)
    const result2 = await getDataFromCacheOrSource(dataKey);
    console.log(`[Cache] Result 2: ${result2}\n`);

    // Wait for cache to expire (or manually delete) and try again
    console.log("[Cache] Waiting for cache to expire...");
    await new Promise(resolve => setTimeout(resolve, 65000)); // Uncomment to test cache expiration
    const result3 = await getDataFromCacheOrSource(dataKey);
    console.log(`[Cache] Result 3 (after expiration): ${result3}\n`);

    // In a real app, keep client connected
    // await (await getRedisClient()).quit();
}

// runCachingExample().catch(console.error); // Call this function when needed
3.5. Scalable Deployment (Redis Cluster/Sentinel)
The core Redis commands remain the same, but the client connection setup changes to connect to a resilient endpoint.

Redis Cluster: Use createCluster and provide an array of seed nodes. The client handles routing commands to the correct shard based on the key.
Redis Sentinel: Use createClient and provide an array of Sentinel addresses and the service name of the master set. The client gets the current master address from Sentinels.
TypeScript

import { createClient, createCluster } from '@redis/client';
// ... other imports needed

// Example connection using @redis/client with Redis Cluster
// async function getRedisClusterClient() {
//     const clusterClient = createCluster({
//         rootNodes: [
//             { url: 'redis://localhost:7000' }, // Seed node 1
//             { url: 'redis://localhost:7001' }, // Seed node 2
//             // ... other seed nodes for discovery
//         ],
//         // Optional: specify readFrom to balance reads across replicas
//         // readFrom: 'replica'
//     });
//     await clusterClient.connect();
//     console.log('Connected to Redis Cluster');
//     return clusterClient; // Use this client for all operations
// }

// Example connection using @redis/client with Redis Sentinel
// async function getRedisSentinelClient() {
//      const sentinelClient = createClient({
//          sentinels: [
//              { host: 'localhost', port: 26379 }, // Sentinel instance 1
//              { host: 'localhost', port: 26380 }, // Sentinel instance 2
//              // ... other sentinel instances
//          ],
//          name: 'mymaster', // The service name Sentinel monitors (defined in sentinel.conf)
//          // Optional: specify readPreference for Sentinel clients (e.g., 'replica', 'master')
//          // readPreference: 'replica'
//      });
//      await sentinelClient.connect();
//      console.log('Connected to Redis Sentinel');
//      return sentinelClient; // Use this client for all operations
// }

// Your `redisClient.ts` would need logic to switch between these connection types based on configuration (e.g., environment variables).
// The core command calls (xAdd, hSet, ft().search, get, etc.) would be the same on the returned client/clusterClient/sentinelClient object, as they share a common interface.
4. Redis-Based Coordination for Multi-Agent Code Collaboration
This section details how the core Redis patterns are combined to coordinate multiple distributed agents, specifically in the context of VS Code extensions collaborating on a shared codebase. These patterns are implemented within the VS Code extension process, interacting with Redis and the VS Code APIs.

Challenges & Redis Solutions:

Task Distribution: Redis Streams (reliable queue, consumer groups).
Shared State: Redis Hashes/JSON for a central task registry, agent status.
Concurrency: Redis Locks (SET NX PX + Lua script) for safe resource access (e.g., files).
Codebase Understanding: Redis Stack (RediSearch/Vector Search) for a shared, queryable index of the codebase (semantic search, RAG).
Proposed Architecture:

Each running VS Code extension instance acts as an independent agent worker. They all connect to the same central Redis instance.

Task Queue: Agents consume tasks from a shared task stream (agent_tasks) using a consumer group (code_agents_group). XAUTOCLAIM is used to recover tasks from failed agent instances.
Task Registry: A central Redis Hash (agent:tasks:registry) stores detailed metadata and the current status (pending, assigned, in-progress, completed, failed) for each task ID, providing a single source of truth accessible to all agents and monitoring tools.
File Locking: Before an agent modifies a file, it attempts to acquire a distributed lock for that file path in Redis. This ensures only one agent performs write operations on a specific file at any given time.
Code Index: A RediSearch index (code_index) stores indexed code chunks and their embeddings. Agents query this index to get context or find relevant code using text or vector similarity search, supporting RAG capabilities.
VS Code API Interaction: Agents use the VS Code Extension API (vscode) to read files, apply edits, show notifications, etc., after acquiring necessary locks.
TypeScript Snippets for Coordination Logic (within an Agent Extension):

These functions are designed to be integrated into your extension's main logic and task processing loops.

4.1. Task Registry (Redis Hash)
Used to track the status and details of all tasks being processed by the agent swarm, providing persistence and shared visibility.

TypeScript

import { getRedisClient } from './redisClient';

const taskRegistryKey = 'agent:tasks:registry'; // Hash key to store all tasks

interface CodeTask {
    taskId: string; // Unique ID for the task (Ideally linked to the stream message ID or a UUID)
    type: 'refactor' | 'implement' | 'review' | 'analyze' | string; // Task category
    filePath: string; // Primary file the task relates to
    description: string; // Human-readable description
    assignedAgentId?: string; // ID of the agent currently assigned (present when status is not 'pending' or 'completed')
    status: 'pending' | 'assigned' | 'in-progress' | 'completed' | 'failed' | 'cancelled';
    createdAt: number; // Timestamp of creation
    updatedAt: number; // Timestamp of last update
    errorMessage?: string; // If status is 'failed'
    streamMessageId?: string; // Link back to the Redis Stream message ID
    // ... other task-specific data (e.g., refactoring instructions, feature description, parameters for LLM)
}

/**
 * Updates the status and details of a task in the shared Redis registry.
 */
async function updateTaskStatus(taskId: string, status: CodeTask['status'], assignedAgentId?: string | null, errorMessage?: string | null): Promise<void> {
    const client = await getRedisClient();
    const taskFieldKey = `task:${taskId}`; // Field key within the registry Hash

    try {
        // Retrieve current task state to merge updates
        const taskJson = await client.hGet(taskRegistryKey, taskFieldKey);
        let task: CodeTask;

        if (taskJson) {
            task = JSON.parse(taskJson);
        } else {
            // This case shouldn't happen if tasks are registered before enqueuing, but handle defensively.
            console.warn(`[Task Registry] Task ${taskId} not found in registry, creating minimal entry based on update attempt.`);
             task = {
                 taskId: taskId,
                 type: 'unknown', // Default type
                 filePath: 'unknown', // Default path
                 description: `Details missing for task ${taskId}`,
                 status: 'pending', // Default status
                 createdAt: Date.now(),
                 updatedAt: Date.now(),
             };
        }

        task.status = status;
        task.updatedAt = Date.now();
        if (assignedAgentId !== undefined) {
            // Use null to explicitly clear assignment
             task.assignedAgentId = assignedAgentId === null ? undefined : assignedAgentId;
        }
         if (errorMessage !== undefined) {
            // Use null to explicitly clear error
            task.errorMessage = errorMessage === null ? undefined : errorMessage;
         }

        // Store the updated task object as a JSON string in the Hash field
        await client.hSet(taskRegistryKey, taskFieldKey, JSON.stringify(task));
        console.log(`[Task Registry] Updated status for task ${taskId} to ${status}`);

    } catch (error) {
        console.error(`[Task Registry] Failed to update status for task ${taskId}:`, error);
        throw error; // Re-throw
    }
}

/**
 * Retrieves the full details of a task from the registry.
 */
async function getTaskDetails(taskId: string): Promise<CodeTask | null> {
     const client = await getRedisClient();
     const taskFieldKey = `task:${taskId}`;
     try {
         const taskJson = await client.hGet(taskRegistryKey, taskFieldKey);
         if (taskJson) {
             return JSON.parse(taskJson) as CodeTask;
         }
         return null;
     } catch (error) {
         console.error(`[Task Registry] Failed to get details for task ${taskId}:`, error);
         throw error;
     }
}

/**
 * Registers a new task in the registry and adds it to the stream.
 * This ensures the task state exists before processing begins.
 */
async function registerAndEnqueueNewTask(task: Omit<CodeTask, 'status' | 'assignedAgentId' | 'createdAt' | 'updatedAt' | 'errorMessage' | 'streamMessageId'>): Promise<string | undefined> {
     const client = await getRedisClient();
     const taskId = task.taskId; // Assuming taskId is generated uniquely before this call (e.g., UUID)
     const taskFieldKey = `task:${taskId}`;
     const taskStream = 'agent_tasks'; // The stream used for task distribution

     const initialTaskState: CodeTask = {
         ...task,
         status: 'pending',
         createdAt: Date.now(),
         updatedAt: Date.now(),
     };

     // Use a transaction to ensure atomicity if possible, though hSet then xAdd is common.
     // Simple approach: set registry, then add to stream.
     try {
         // Add to registry
         await client.hSet(taskRegistryKey, taskFieldKey, JSON.stringify(initialTaskState));
         console.log(`[Task Registry] Registered new task: ${taskId}`);

         // Add to stream for processing
         const messagePayload = {
             type: 'TASK_REQUEST', // Message type for the stream
             taskId: taskId, // Link stream message back to registry task
             source: initialTaskState.source || 'system', // Assuming source is part of input task
             target: 'code_agents_group', // Target a group for stream consumption
             payload: JSON.stringify(task), // Full task details in stream message payload
             timestamp: new Date().toISOString(),
         };
         const streamMessageId = await client.xAdd(taskStream, '*', messagePayload);
         console.log(`[Task Registry] Enqueued task ${taskId} with stream message ID: ${streamMessageId}`);

         // Optionally update registry task with streamMessageId
         await client.hSet(taskRegistryKey, taskFieldKey, JSON.stringify({ ...initialTaskState, streamMessageId: streamMessageId }));

         return streamMessageId;

     } catch (error) {
          console.error(`[Task Registry] Failed to register and enqueue new task ${taskId}:`, error);
          // Cleanup if registration succeeded but enqueue failed? Depends on desired atomicity.
          // await client.hDel(taskRegistryKey, taskFieldKey); // Optional cleanup
          throw error;
     }
}

// Example usage (called when a user triggers a task or another agent creates one):
/*
async function handleUserInitiatedRefactor() {
    const taskId = crypto.randomUUID(); // Generate a unique ID
    const filePath = await getUserSelectedFilePath(); // Get file from VS Code API
    const description = await getUserInput('Enter refactor description:'); // Get description

    if (filePath && description) {
        const newTask: Omit<CodeTask, 'status' | 'assignedAgentId' | 'createdAt' | 'updatedAt' | 'errorMessage' | 'streamMessageId'> = {
            taskId: taskId,
            type: 'refactor',
            filePath: filePath,
            description: description,
            source: agentInstanceId, // Your agent's ID
            // Add other relevant data like specific instructions, scope, etc.
        };
        try {
             await registerAndEnqueueNewTask(newTask);
             vscode.window.showInformationMessage(`Refactor task ${taskId} enqueued.`);
        } catch (e) {
             vscode.window.showErrorMessage(`Failed to enqueue refactor task: ${e.message}`);
        }
    }
}
// Example trigger: vscode.commands.registerCommand('thefuse.enqueueRefactorTask', handleUserInitiatedRefactor);
*/

4.2. Distributed Locks
Using SET key value NX PX combined with a safe Lua script for releasing locks. Essential for preventing concurrent modifications of the same file by different agent instances.

TypeScript

import { getRedisClient } from './redisClient';

// Unique identifier for this agent instance (ideally generated once per extension instance startup)
const agentInstanceId = `agent_${process.pid}_${Date.now()}`; // Example ID

/**
 * Attempts to acquire a distributed lock for a given resource (e.g., file path).
 * @param lockKey A unique key for the resource (e.g., `lock:file:/path/to/file.ts`)
 * @param ownerId A unique identifier for the lock owner (this agent instance ID)
 * @param expirationMillis Lock expiration time in milliseconds to prevent deadlocks
 * @returns True if the lock was acquired, false otherwise.
 */
async function acquireFileLock(lockKey: string, ownerId: string = agentInstanceId, expirationMillis: number = 30000): Promise<boolean> {
    const client = await getRedisClient();
    try {
        // SET command: Atomically set the key with ownerId as value
        // NX: Only set if the key does NOT exist (exclusive acquire)
        // PX: Set expiration time in milliseconds (automatic release if the agent crashes)
        const result = await client.set(lockKey, ownerId, {
            NX: true, // Stands for Not eXists
            PX: expirationMillis, // Stands for expire in milli-seconds
        });

        // The SET command with NX returns null if the key already exists, otherwise 'OK'.
        return result === 'OK';

    } catch (error) {
        console.error(`[Lock] Error attempting to acquire lock ${lockKey} for ${ownerId}:`, error);
        throw error; // Re-throw
    }
}

/**
 * Safely releases a distributed lock, only if the caller is the current owner.
 * Uses a Lua script for atomic check-and-delete.
 * @param lockKey The key for the lock resource.
 * @param ownerId The expected owner ID (this agent instance ID).
 * @returns True if the lock was successfully released, false otherwise (e.g., not the owner, or lock expired).
 */
async function releaseFileLock(lockKey: string, ownerId: string = agentInstanceId): Promise<boolean> {
    const client = await getRedisClient();
    // Lua script for safe release:
    // 1. Check if the lock key exists and its value matches the ownerId.
    // 2. If yes, delete the key and return 1.
    // 3. If no, return 0.
    // This is atomic, preventing a race condition where an agent might delete a lock
    // that expired and was re-acquired by another agent.
    const luaScript = `
        if redis.call("get",KEYS[1]) == ARGV[1] then
            return redis.call("del",KEYS[1])
        else
            return 0
        end
    `;
    try {
         // EVAL command: Execute the Lua script atomically on the Redis server.
         // KEYS[1]: The first key argument passed to the script (the lockKey).
         // ARGV[1]: The first non-key argument passed to the script (the ownerId).
         const result = await client.eval(luaScript, {
             keys: [lockKey], // Pass the lock key as a KEYS argument
             arguments: [ownerId], // Pass the owner ID as an ARGV argument
         });

         // The eval command returns the value returned by the Lua script (1 or 0).
         return result === 1;

    } catch (error) {
        console.error(`[Lock] Error attempting to release lock ${lockKey} for ${ownerId}:`, error);
        throw error;
    }
}

// Example usage within your task processing logic (part of the consumer loop):
/*
// Assume task object is available from stream consumption, and it includes task.filePath
// Assume agentInstanceId is defined for this running agent instance
const filePathToEdit = task.filePath;
const fileLockKey = `lock:file:${filePathToEdit}`;
const lockAcquireTimeout = 5000; // How long to wait trying to acquire the lock (simple approach, could loop and retry)
const lockExpiration = 30000; // Lock expires after 30 seconds if not released

// Update task status to assigned/in-progress before attempting lock (optional, but good practice)
await updateTaskStatus(task.taskId, 'assigned', agentInstanceId);

const lockAcquired = await acquireFileLock(fileLockKey, agentInstanceId, lockExpiration);

if (lockAcquired) {
    console.log(`Agent ${agentInstanceId} acquired lock for ${filePathToEdit} for task ${task.taskId}.`);
    await updateTaskStatus(task.taskId, 'in-progress', agentInstanceId); // Confirm in-progress after lock

    try {
        // --- Perform file modifications using VS Code API ---
        // Requires importing the 'vscode' module in your extension.
        // Ensure this code runs within a function that has access to the VS Code API context.

        // const vscode = require('vscode');
        // const fileUri = vscode.Uri.file(filePathToEdit);
        // const fileContent = (await vscode.workspace.fs.readFile(fileUri)).toString(); // Read file content
        // console.log(`Read file ${filePathToEdit}`);

        // // Example: Prepend a comment (replace with actual agent logic)
        // const edits = [vscode.TextEdit.insert(new vscode.Position(0, 0), `// [${agentInstanceId}] Processed task ${task.taskId} at ${new Date().toISOString()}\n`)];
        // const workspaceEdit = new vscode.WorkspaceEdit();
        // workspaceEdit.set(fileUri, edits);

        // // Apply the edits to the file in VS Code
        // const editsApplied = await vscode.workspace.applyEdit(workspaceEdit);
        // if (editsApplied) {
        //     console.log(`Applied edits to ${filePathToEdit} for task ${task.taskId}.`);
        // } else {
        //     console.error(`Failed to apply edits to ${filePathToEdit} for task ${task.taskId}.`);
        //     throw new Error('Failed to apply edits'); // Indicate failure
        // }
        // --- End file modifications ---

        // Assuming success:
        await updateTaskStatus(task.taskId, 'completed', agentInstanceId);

    } catch (processingError: any) {
        console.error(`Error processing task ${task.taskId} for file ${filePathToEdit}:`, processingError);
        // Update task status to failed and record the error message
        await updateTaskStatus(task.taskId, 'failed', agentInstanceId, processingError.message);
        // Re-throw the error if it needs to be handled further up (e.g., for DLQ logic in the consumer)
        throw processingError;
    } finally {
        // ALWAYS release the lock in a finally block to ensure it happens even if errors occur
        const lockReleased = await releaseFileLock(fileLockKey, agentInstanceId);
        if (lockReleased) {
            console.log(`Agent ${agentInstanceId} released lock for ${filePathToEdit}.`);
        } else {
            console.warn(`Agent ${agentInstanceId} failed to release lock for ${filePathToEdit}. Might have expired or owned by another?`);
        }
    }
} else {
    console.warn(`Agent ${agentInstanceId} could not acquire lock for ${filePathToEdit} for task ${task.taskId}.`);
    // Logic to handle not acquiring lock:
    // 1. Update task status back to 'pending' or 'assigned' and remove assignment.
    //    await updateTaskStatus(task.taskId, 'pending', undefined); // Unassign
    // 2. Do NOT acknowledge the stream message yet if you plan to retry this specific message later.
    //    If using XAUTOCLAIM with min-idle-time, the message will become claimable by another agent after the timeout.
    // 3. Potentially log this as an event indicating resource contention.
    throw new Error(`Could not acquire lock for ${filePathToEdit}`); // Indicate failure to the consumer loop
}
*/

4.3. Codebase Indexing and Search (RediSearch/Vector Search)
Building and querying a RediSearch index over the codebase allows agents to perform semantic search and retrieve relevant code snippets for context (RAG). This index is a shared resource.

TypeScript

import { getRedisClient } from './redisClient'; // Use the extended client type
import { SearchReply, SchemaFieldTypes, VectorAlgorithms } from '@redis/search';

// Assuming the index 'code_index' exists and has a vector field 'embedding'
// Index creation is similar to vectorDbExample, adjusted for code chunks.
// Schema might look like: { file_path: TEXT, chunk_id: TAG, chunk_content: TEXT, embedding: VECTOR }
const codeIndexName = 'code_index';
const codePrefix = 'code_chunk:'; // Prefix for keys representing code chunks
const codeVectorFieldName = 'embedding';
const codeVectorDimensions = 768; // Example embedding dimension (e.g., for a common model like miniLM)

// Assume you have an embedding function available in your agent's environment
// async function getEmbeddingForText(text: string): Promise<Float32Array> { /* ... Call your embedding model */ }

/**
 * Finds relevant code snippets using vector similarity and optional text filters.
 * Useful for providing context (RAG) to LLMs during agent tasks.
 * @param queryText The text query (e.g., description of problem, function name).
 * @param k The number of nearest neighbors to retrieve.
 * @returns An array of relevant code chunk documents.
 */
async function findRelevantCodeSnippets(queryText: string, k: number = 5): Promise<any[]> { // Adjust return type based on indexed document structure
    const client = await getRedisClient();

    try {
        // 1. Get embedding for the query text using your embedding model
        // Replace this with your actual embedding model call
        // const queryEmbedding = await getEmbeddingForText(queryText);
        // const queryVectorBuffer = Buffer.from(queryEmbedding.buffer);

         // Placeholder embedding buffer for demonstration
         const queryVectorBuffer = Buffer.from(new Float32Array(codeVectorDimensions).fill(0.1).buffer); // Replace with actual embedding buffer


        // 2. Perform KNN Vector Search on the code index
        // Query structure: `[optional_text_filters]=>[KNN k @vector_field $vec_param AS score_alias]`
        // `*` matches all documents initially. Add filters like `@file_path:{"*.ts"}` etc.
        const query = `*=>[KNN ${k} @${codeVectorFieldName} $vec_param AS vector_score]`;

        const results: SearchReply = await client.ft(codeIndexName).search(query, {
            QUERY: {
                PARAMS: {
                    vec_param: queryVectorBuffer
                },
                RETURN: ['file_path', 'chunk_content', 'vector_score'], // Return relevant fields
                SORTBY: '@vector_score', // Sort by score (DESC for COSINE/IP, ASC for L2). '@' prefix often needed for aliases.
                DIALECT: 2, // Use Dialect 2 for modern features like PARAMS
            }
        });

        console.log(`[Code Search] Found ${results.total} relevant code chunks for query.`);
        const documents = results.documents?.map((doc: any) => doc.value) || []; // Extract document values

        // If vector_score is similarity (COSINE/IP), results might need client-side sort if RediSearch sort is ASC
        // If using SORTBY '@vector_score' DESC in query, this might not be needed.
        // Assuming '@vector_score' in SORTBY works as intended for the metric.
        // If not, manually sort: documents.sort((a, b) => b.vector_score - a.vector_score);

        return documents;
    } catch (error: any) {
        console.error('[Code Search] Error performing code search:', error);
        if (error.message && error.message.includes('Unknown Index name')) {
             console.error(`[Code Search] Make sure the index "${codeIndexName}" exists and is configured correctly.`);
        }
        throw error; // Re-throw
    }
}

// Example usage within an agent's task processing logic:
/*
// Assume agent needs context for a refactoring task
// const taskDescription = task.description;
// const relevantCodeContext = await findRelevantCodeSnippets(taskDescription, 5);
// console.log("Context for LLM:", relevantCodeContext);
// // Pass relevantCodeContext (e.g., formatted as JSON or Markdown) to the LLM along with the task prompt.
*/


/**
 * Indexes a code chunk in RediSearch. This would likely be run by a dedicated indexer agent
 * or triggered by file change events within the VS Code extension.
 * @param filePath The path of the file.
 * @param chunkId A unique ID for this specific chunk within the file.
 * @param chunkContent The source code content of the chunk.
 */
/*
async function indexCodeChunk(filePath: string, chunkId: string, chunkContent: string): Promise<void> {
     const client = await getRedisClient();
     const key = `${codePrefix}${filePath}:${chunkId}`; // Unique key using the defined prefix

     try {
         // 1. Get embedding for the chunk content
         // const embedding = await getEmbeddingForText(chunkContent);
         // const embeddingBuffer = Buffer.from(embedding.buffer);

         // Placeholder embedding buffer for demonstration
         const embeddingBuffer = Buffer.from(new Float32Array(codeVectorDimensions).fill(0.5).buffer); // Replace with actual embedding


         // 2. Use HSET to store the chunk data and vector.
         // The RediSearch index definition on the 'code_chunk:' prefix will automatically index this Hash.
         await client.hSet(key, {
             file_path: filePath,
             chunk_id: chunkId, // Tag field for chunk ID
             chunk_content: chunkContent,
             embedding: embeddingBuffer, // Store vector as Buffer
         });
         console.log(`[Code Indexer] Indexed chunk ${key}`);
     } catch (error) {
         console.error(`[Code Indexer] Failed to index chunk ${key}:`, error);
         throw error; // Re-throw
     }
}
*/

4.4. Implementing the Worker Loop and VS Code Interaction
The core of an agent extension instance is a loop that consumes tasks from the stream, interacts with Redis for coordination, and uses the VS Code API to perform actions.

Conceptual Worker Loop Structure (within your extension's activate function):

TypeScript

import * as vscode from 'vscode'; // Import the VS Code API
import { getRedisClient } from './redisClient';
// Import other functions from Sections 4.1, 4.2, 4.3
// import { updateTaskStatus, getTaskDetails } from './taskRegistry';
// import { acquireFileLock, releaseFileLock } from './distributedLocks';
// import { findRelevantCodeSnippets } from './codeIndexer'; // Assuming you have an indexer service

const taskStream = 'agent_tasks';
const consumerGroupName = 'code_agents_group';
const agentInstanceId = `agent_instance_${process.pid}_${Date.now()}`; // Unique ID for this instance

async function startAgentWorker(context: vscode.ExtensionContext) { // Pass VS Code context
    const client = await getRedisClient();

    // Ensure consumer group exists on startup
    try {
        await client.xGroupCreate(taskStream, consumerGroupName, '0', { MKSTREAM: true });
        console.log(`[Worker ${agentInstanceId}] Consumer group '${consumerGroupName}' ensured.`);
    } catch (error: any) {
         if (error.message && error.message.includes('BUSYGROUP')) {
             console.log(`[Worker ${agentInstanceId}] Consumer group '${consumerGroupName}' already exists.`);
         } else {
             console.error(`[Worker ${agentInstanceId}] Failed to create consumer group:`, error);
             // Handle fatal error: Maybe show error to user and deactivate extension
             vscode.window.showErrorMessage(`Agent failed to start: Could not setup message queue (${error.message})`);
             return; // Stop activation
         }
    }


    console.log(`[Worker ${agentInstanceId}] Starting task consumption loop...`);

    // Store the consumption loop promise and client so they can be properly disposed on deactivation
    let isProcessing = true;
    context.subscriptions.push({ dispose: () => { isProcessing = false; client.quit(); console.log(`[Worker ${agentInstanceId}] Shutting down.`); } });

    // Main consumption loop
    while (isProcessing) {
        try {
            // XREADGROUP to get next pending or new message
            const messages = await client.xReadGroup(consumerGroupName, agentInstanceId, {
                key: taskStream,
                id: '>', // Read new messages
            }, {
                count: 1, // Process one at a time
                block: 2000, // Block up to 2s
            });

            if (messages && messages.length > 0) {
                const message = messages[0].messages[0]; // Get the single message

                const taskMessageString = message.message['payload'];
                const streamMessageId = message.id;

                if (!taskMessageString) {
                     console.warn(`[Worker ${agentInstanceId}] Received message ${streamMessageId} with no payload. Acknowledging.`);
                     await client.xAck(taskStream, consumerGroupName, streamMessageId);
                     continue; // Get next message
                }

                let task: CodeTask;
                try {
                    const rawTaskPayload = JSON.parse(taskMessageString);
                    // Ensure task has at least a taskId. If adding via stream directly, messageId can be task ID.
                    const taskId = rawTaskPayload.taskId || streamMessageId;
                    task = {
                         taskId: taskId,
                         streamMessageId: streamMessageId,
                         ...rawTaskPayload, // Merge other properties
                         status: 'assigned', // Initial status upon receiving
                         updatedAt: Date.now(),
                         createdAt: rawTaskPayload.createdAt || Date.now(), // Use creation timestamp if present
                         type: rawTaskPayload.type || 'unknown', // Ensure type is present
                         filePath: rawTaskPayload.filePath || 'unknown', // Ensure path is present
                         description: rawTaskPayload.description || 'No description', // Ensure description
                    };


                    console.log(`[Worker ${agentInstanceId}] Received task ${task.taskId} (Msg ID: ${streamMessageId}).`);

                    // Ensure task exists in registry and mark as assigned
                    await updateTaskStatus(task.taskId, 'assigned', agentInstanceId);

                    // --- Core Task Processing ---
                    // This is the main logic block for the task. It includes locking.
                    const fileLockKey = `lock:file:${task.filePath}`;
                    const lockExpiration = 60000; // Lock expires after 60 seconds

                    let lockAcquired = false;
                    try {
                        // Attempt to acquire the file lock
                        lockAcquired = await acquireFileLock(fileLockKey, agentInstanceId, lockExpiration);

                        if (!lockAcquired) {
                            console.warn(`[Worker ${agentInstanceId}] Could not acquire lock for ${task.filePath} for task ${task.taskId}. Skipping for now.`);
                            // Task remains assigned in registry. It will become pending in stream after timeout,
                            // or another agent can claim it via XAUTOCLAIM.
                            // Do NOT acknowledge the stream message yet.
                            continue; // Skip processing this message and get next
                        }

                        console.log(`[Worker ${agentInstanceId}] Acquired lock for ${task.filePath}. Processing task ${task.taskId}...`);
                        await updateTaskStatus(task.taskId, 'in-progress', agentInstanceId); // Confirm in-progress after lock


                        // Use VS Code API to perform actions on the file
                        const fileUri = vscode.Uri.file(task.filePath);
                        // Example: Read file content
                        // const fileContent = (await vscode.workspace.fs.readFile(fileUri)).toString();
                        // console.log(`Read ${task.filePath} content.`);

                        // Example: Find relevant code context using RediSearch
                        // try {
                        //      const relevantContext = await findRelevantCodeSnippets(task.description, 3);
                        //      console.log(`Found ${relevantContext.length} relevant code snippets.`);
                        //      // Use relevantContext in your LLM prompt
                        // } catch (searchError) {
                        //      console.error(`Error searching code index for task ${task.taskId}:`, searchError);
                        //      // Decide how to handle search failure (e.g., proceed without RAG)
                        // }


                        // Example: Apply a simple edit (prepend comment)
                        // const edits = [vscode.TextEdit.insert(new vscode.Position(0, 0), `// [${agentInstanceId}] Processed task ${task.taskId} at ${new Date().toISOString()}\n`)];
                        // const workspaceEdit = new vscode.WorkspaceEdit();
                        // workspaceEdit.set(fileUri, edits);

                        // const editsApplied = await vscode.workspace.applyEdit(workspaceEdit);
                        // if (!editsApplied) {
                        //     throw new Error('Failed to apply edits in VS Code.');
                        // }
                        // console.log(`Applied edits for task ${task.taskId}.`);


                        // Task completed successfully
                        await updateTaskStatus(task.taskId, 'completed', agentInstanceId);
                        console.log(`[Worker ${agentInstanceId}] Task ${task.taskId} completed successfully.`);

                        // Acknowledge the stream message only after successful processing and status update
                        await client.xAck(taskStream, consumerGroupName, streamMessageId);
                        console.log(`[Worker ${agentInstanceId}] Acknowledged message ${streamMessageId} for task ${task.taskId}.`);


                    } catch (taskProcessingError: any) {
                        console.error(`[Worker ${agentInstanceId}] Error processing task ${task.taskId} (Msg ID: ${streamMessageId}):`, taskProcessingError);

                        // Update task status to failed
                        await updateTaskStatus(task.taskId, 'failed', agentInstanceId, taskProcessingError.message);
                        console.log(`[Worker ${agentInstanceId}] Task ${task.taskId} marked as failed.`);

                        // --- Error Handling and DLQ ---
                        // Decide whether to acknowledge (move to DLQ) or not acknowledge (retry by another agent after timeout)
                        // If acknowledging and moving to DLQ:
                        // try {
                        //      await client.xAdd(`${taskStream}:dlq`, '*', { originalMessageId: streamMessageId, error: taskProcessingError.message, ...message.message });
                        //      console.log(`[Worker ${agentInstanceId}] Moved message ${streamMessageId} to DLQ.`);
                        //      await client.xAck(taskStream, consumerGroupName, streamMessageId); // Acknowledge from main stream
                        //      console.log(`[Worker ${agentInstanceId}] Acknowledged message ${streamMessageId} from main stream after DLQ move.`);
                        // } catch (dlqError) {
                        //      console.error(`[Worker ${agentInstanceId}] Failed to move message ${streamMessageId} to DLQ:`, dlqError);
                        //      // If DLQ fails, decide whether to acknowledge anyway or leave it (risks blocking group)
                        //      // For robustness, might leave it if DLQ fails, hoping another agent can eventually handle it or DLQ system recovers.
                        //      // Or acknowledge to avoid blocking if DLQ is non-critical path.
                        //       await client.xAck(taskStream, consumerGroupName, streamMessageId); // Example: Acknowledge anyway
                        // }
                        // --- End Error Handling ---

                        // For this basic example, just acknowledge the failed message from the stream
                        await client.xAck(taskStream, consumerGroupName, streamMessageId);
                         console.log(`[Worker ${agentInstanceId}] Acknowledged failed message ${streamMessageId} for task ${task.taskId}.`);


                    } finally {
                         // ALWAYS attempt to release the lock in the finally block
                         if (lockAcquired) {
                              const lockReleased = await releaseFileLock(fileLockKey, agentInstanceId);
                              if (lockReleased) {
                                   console.log(`[Worker ${agentInstanceId}] Released lock for ${task.filePath}.`);
                              } else {
                                   console.warn(`[Worker ${agentInstanceId}] Failed to release lock for ${task.filePath}. It might have expired.`);
                              }
                         }
                    }
                    // --- End Core Task Processing ---


                } catch (messageParsingOrSetupError: any) {
                    console.error(`[Worker ${agentInstanceId}] Error parsing message ${streamMessageId} or initial setup:`, messageParsingOrSetupError);
                    // Acknowledge malformed messages to prevent them from blocking the consumer
                    await client.xAck(taskStream, consumerGroupName, streamMessageId);
                    console.log(`[Worker ${agentInstanceId}] Acknowledged malformed message ${streamMessageId}.`);
                }

            } else {
                // No new messages were read within the BLOCK timeout.
                // This is a good time to check for and claim pending messages
                // assigned to consumers that might have crashed or become unresponsive.
                // Use XAUTOCLAIM here.
                const minIdleTimeMillis = 60000; // e.g., 60 seconds idle
                const claimCount = 1; // Claim one pending message at a time

                try {
                    const claimResult = await client.xAutoClaim(taskStream, consumerGroupName, agentInstanceId, minIdleTimeMillis, {
                        count: claimCount,
                        // MINID: '0-0', // Start scanning from the beginning of the pending entries list
                    });

                    if (claimResult && claimResult.messages && claimResult.messages.length > 0) {
                         console.log(`[Worker ${agentInstanceId}] Claimed ${claimResult.messages.length} pending message(s).`);
                        // Process the claimed messages just like new messages
                        for (const claimedMessage of claimResult.messages) {
                             console.log(`[Worker ${agentInstanceId}] Processing claimed message ${claimedMessage.id}...`);
                             // Note: processStreamMessage needs messageId and messageData structure.
                             // claimedMessage has { id: string, message: { [key: string]: string } }
                             await processStreamMessage(claimedMessage.id, claimedMessage.message);
                        }
                         // The claimed messages are automatically moved from pending to current by XAUTOCLAIM
                         // and will be acknowledged in processStreamMessage.

                    } else if (claimResult && claimResult.start === '0-0') {
                        // XAUTOCLAIM returned 0 messages but indicated it scanned from the start.
                        // console.log(`[Worker ${agentInstanceId}] No pending messages found.`);
                    }


                } catch (claimError) {
                    console.error(`[Worker ${agentInstanceId}] Error during XAUTOCLAIM:`, claimError);
                    // Continue the loop, hoping the issue resolves
                }
            }

        } catch (readLoopError: any) {
            // This catches errors from client.xReadGroup or XAUTOCLAIM itself (e.g., connection errors)
            console.error(`[Worker ${agentInstanceId}] Error during stream read loop:`, readLoopError);
            // Wait before retrying the read loop to avoid a tight CPU loop
            await new Promise(resolve => setTimeout(resolve, 5000));
        }
    }
    console.log(`[Worker ${agentInstanceId}] Consumption loop stopped.`);
}

// To start the worker when your extension activates:
// export function activate(context: vscode.ExtensionContext) {
//      console.log('The New Fuse Agent Extension activating...');
//      // Initialize Redis client and start the worker loop
//      startAgentWorker(context).catch(error => {
//           console.error("Failed to start agent worker:", error);
//           vscode.window.showErrorMessage(`Failed to start The New Fuse Agent: ${error.message}`);
//      });

//      // Register VS Code commands here (see Section 4.6)
//      // context.subscriptions.push(vscode.commands.registerCommand(...));
// }

// export function deactivate() {
//      console.log('The New Fuse Agent Extension deactivating.');
//      // The context.subscriptions mechanism will handle client shutdown
// }
4.5. CodeIndexer: RediSearch Integration
A service or part of your agent responsible for building and maintaining the RediSearch index of the codebase. Agents query this index.

src/services/CodeIndexer.ts (Conceptual, needs full implementation including chunking, embedding, and indexing logic)

TypeScript

import { getRedisClient } from '../redisClient'; // Adjust path
import { SchemaFieldTypes, VectorAlgorithms } from '@redis/search';
import * as vscode from 'vscode'; // Requires VS Code API

const codeIndexName = 'code_index';
const codePrefix = 'code_chunk:';
const codeVectorFieldName = 'embedding';
const codeVectorDimensions = 768; // Ensure this matches your embedding model

interface CodeChunkDocument {
    file_path: string; // TEXT
    chunk_id: string; // TAG or TEXT depending on search needs
    chunk_content: string; // TEXT
    start_line: number; // NUMERIC (optional, but useful)
    end_line: number; // NUMERIC (optional)
    embedding: Buffer; // VECTOR (FLOAT32)
    // Add other relevant metadata: language, commit_hash, last_indexed_timestamp etc.
}

export class CodeIndexer {
    // The Redis client is obtained via getRedisClient()
    private client: ReturnType<typeof getRedisClient> | null = null;

    async initialize(): Promise<void> {
        this.client = await getRedisClient();
        await this.createIndex();
    }

    private async createIndex(): Promise<void> {
         const client = await this.client;
         if (!client) throw new Error("Redis client not initialized for indexer.");

         try {
             const schema = {
                 file_path: { type: SchemaFieldTypes.TEXT },
                 chunk_id: { type: SchemaFieldTypes.TAG }, // Use TAG if you filter/group by chunk_id
                 chunk_content: { type: SchemaFieldTypes.TEXT },
                 start_line: { type: SchemaFieldTypes.NUMERIC },
                 end_line: { type: SchemaFieldTypes.NUMERIC },
                 [codeVectorFieldName]: { // Use dynamic field name
                     type: SchemaFieldTypes.VECTOR,
                     AS: codeVectorFieldName, // Alias in results
                     ALGORITHM: VectorAlgorithms.FLAT, // Or HNSW
                     ATTRIBUTES: {
                         TYPE: 'FLOAT32',
                         DIM: codeVectorDimensions,
                         DISTANCE_METRIC: 'COSINE', // Must match embedding space
                     },
                 } as const,
             };

             await client.ft(codeIndexName).create(schema, {
                  ON: 'HASH',
                  PREFIX: codePrefix,
                  // Optional: Other index parameters
             });
             console.log(`[CodeIndexer] Index '${codeIndexName}' created or already exists.`);
         } catch (error: any) {
             if (error.message && error.message.includes('Index already exists')) {
                 console.log(`[CodeIndexer] Index '${codeIndexName}' already exists.`);
             } else {
                 console.error('[CodeIndexer] Error creating index:', error);
                 throw error;
             }
         }
    }

    /**
     * Recursively indexes files in the workspace.
     * Needs implementation for file discovery, content reading, chunking, and embedding.
     */
    async indexWorkspace(workspaceRootUri: vscode.Uri): Promise<void> {
         console.log(`[CodeIndexer] Starting indexing for workspace: ${workspaceRootUri.fsPath}`);
         // This is a complex operation requiring:
         // 1. Walking the file system (using vscode.workspace.fs.readDirectory, vscode.Uri).
         // 2. Filtering relevant files (e.g., *.ts, *.js, *.py).
         // 3. Reading file content (vscode.workspace.fs.readFile).
         // 4. Splitting content into smaller, meaningful chunks (code chunking logic).
         // 5. Generating embeddings for each chunk (using an external or local embedding model).
         // 6. Storing each chunk and its metadata (including vector) as a Redis Hash key using `client.hSet`.
         // 7. Deleting keys for files that no longer exist or chunks that changed (requires tracking).

         // Example of processing a single file (conceptual):
         // async indexFile(fileUri: vscode.Uri): Promise<void> {
         //      const content = (await vscode.workspace.fs.readFile(fileUri)).toString();
         //      const chunks = yourChunkingLogic(content); // Implement chunking
         //      for (const chunk of chunks) {
         //           const embedding = await getEmbeddingForText(chunk.content); // Implement embedding
         //           const chunkId = generateUniqueChunkId(fileUri, chunk.start_line); // Unique ID
         //           const key = `${codePrefix}${fileUri.fsPath}:${chunkId}`;
         //           const doc: CodeChunkDocument = {
         //               file_path: fileUri.fsPath,
         //               chunk_id: chunkId,
         //               chunk_content: chunk.content,
         //               start_line: chunk.start_line,
         //               end_line: chunk.end_line,
         //               embedding: Buffer.from(embedding.buffer),
         //           };
         //           await this.client?.hSet(key, doc as any); // Type assertion might be needed
         //           console.log(`[CodeIndexer] Indexed ${key}`);
         //      }
         // }

         console.log('[CodeIndexer] Workspace indexing logic needs full implementation.');
         // Call your indexing logic here, iterating through files
         // For demo, manually add a placeholder document:
         /*
         const placeholderVec = new Float32Array(codeVectorDimensions).fill(0.7);
         const placeholderKey = `${codePrefix}/path/to/example.ts:chunk1`;
          await this.client?.hSet(placeholderKey, {
              file_path: '/path/to/example.ts',
              chunk_id: 'chunk1',
              chunk_content: 'This is a sample code snippet about authentication.',
              start_line: 1,
              end_line: 5,
              embedding: Buffer.from(placeholderVec.buffer)
         } as any);
         console.log(`[CodeIndexer] Added placeholder document: ${placeholderKey}`);
         */

         console.log('[CodeIndexer] Workspace indexing started (conceptual).');
    }

    /**
     * Searches the code index using a text query (full-text search).
     */
    async search(queryText: string): Promise<any[]> {
        const client = await this.client;
        if (!client) throw new Error("Redis client not initialized for indexer.");

        try {
            // Simple full-text search query
            const results: SearchReply = await client.ft(codeIndexName).search(queryText, {
                RETURN: ['file_path', 'chunk_content', 'start_line'],
                // Other options: LIMIT, SORTBY, Filters
            });

            console.log(`[CodeIndexer] Text search for "${queryText}" found ${results.total} matches.`);
             return results.documents?.map((doc: any) => doc.value) || [];

        } catch (error: any) {
            console.error(`[CodeIndexer] Error during text search for "${queryText}":`, error);
            throw error;
        }
    }

     /**
      * Searches the code index using vector similarity (semantic search).
      * This is the implementation from Section 4.3
      */
     async searchSemantic(queryVector: Float32Array, k: number = 5): Promise<any[]> {
         const client = await this.client;
         if (!client) throw new Error("Redis client not initialized for indexer.");

          try {
             const queryVectorBuffer = Buffer.from(queryVector.buffer);
             const query = `*=>[KNN ${k} @${codeVectorFieldName} $vec_param AS vector_score]`;

             const results: SearchReply = await client.ft(codeIndexName).search(query, {
                 QUERY: {
                     PARAMS: { vec_param: queryVectorBuffer },
                     RETURN: ['file_path', 'chunk_content', 'start_line', 'vector_score'],
                     SORTBY: '@vector_score', // Assuming sort by alias works as needed
                     DIALECT: 2,
                 }
             });

             console.log(`[CodeIndexer] Semantic search found ${results.total} matches.`);
             const documents = results.documents?.map((doc: any) => doc.value) || [];
             // Add client-side sort if RediSearch SORTBY doesn't provide desired order for metric
             // For COSINE/IP, sort descending: documents.sort((a, b) => parseFloat(b.vector_score) - parseFloat(a.vector_score));

             return documents;

         } catch (error: any) {
             console.error('[CodeIndexer] Error during semantic search:', error);
             throw error;
         }
     }

    // Add methods for deleting documents (e.g., when files are deleted)
    // async deleteDocument(filePath: string, chunkId: string): Promise<void> { ... }
    // async deleteFileDocuments(filePath: string): Promise<void> { ... }
}

// Example usage within your extension's activation:
// const codeIndexer = new CodeIndexer();
// codeIndexer.initialize().catch(console.error); // Initialize indexer
// context.subscriptions.push({ dispose: () => { /* cleanup indexer if needed */ } });

// Example usage in a command:
// vscode.commands.registerCommand('thefuse.indexWorkspace', async () => {
//     if (vscode.workspace.workspaceFolders && vscode.workspace.workspaceFolders.length > 0) {
//         await codeIndexer.indexWorkspace(vscode.workspace.workspaceFolders[0].uri);
//         vscode.window.showInformationMessage('Workspace indexing initiated.');
//     } else {
//         vscode.window.showWarningMessage('No workspace folder open.');
//     }
// });

// vscode.commands.registerCommand('thefuse.searchCode', async () => {
//     const query = await vscode.window.showInputBox({ prompt: 'Enter search term or question' });
//     if (query) {
//          // Decide whether to use text or semantic search, or both
//          // If semantic: need to get embedding for the query first
//          // const queryEmbedding = await getEmbeddingForText(query);
//          // const results = await codeIndexer.searchSemantic(queryEmbedding);

//         const results = await codeIndexer.search(query); // Example: using text search

//         if (results.length > 0) {
//             const picked = await vscode.window.showQuickPick(
//                 results.map(item => ({
//                     label: `${item.file_path}:${item.start_line}`,
//                     description: item.chunk_content.substring(0, 100) + '...',
//                     detail: `Score: ${item.vector_score ? parseFloat(item.vector_score).toFixed(4) : 'N/A'}`,
//                     item: item // Store the full item
//                 })),
//                 { placeHolder: 'Select a code snippet to open' }
//             );
//             if (picked) {
//                 const uri = vscode.Uri.file(picked.item.file_path);
//                 const range = new vscode.Range(new vscode.Position(picked.item.start_line - 1, 0), new vscode.Position(picked.item.start_line - 1, 0));
//                 const doc = await vscode.workspace.openTextDocument(uri);
//                 await vscode.window.showTextDocument(doc, { selection: range });
//             }
//         } else {
//             vscode.window.showInformationMessage('No code snippets found.');
//         }
//     }
// });

4.6 VS Code Commands
Your package.json defines custom commands that users interact with via the Command Palette. These commands will trigger actions that use the Redis coordination mechanisms (e.g., enqueueing tasks).

Example package.json contribution points:

JSON

// In your extension's package.json

"contributes": {
    "commands": [
        {
            "command": "thefuse.indexWorkspace",
            "title": "The New Fuse: Index Workspace in Redis"
        },
        {
            "command": "thefuse.searchCode",
            "title": "The New Fuse: Search Code in Redis"
        },
        {
            "command": "thefuse.enqueueTask",
            "title": "The New Fuse: Enqueue Generic Task"
        }
        // Add more commands for specific task types (refactor, review, etc.)
    ]
},
"activationEvents": [
    "onCommand:thefuse.indexWorkspace",
    "onCommand:thefuse.searchCode",
    "onCommand:thefuse.enqueueTask",
    "onStartupFinished" // Maybe activate agent worker on startup
]
Your extension's activate function (in extension.ts) will register the implementations for these commands and start the agent's Redis consumer loop.

4.7 Workflow Example
This end-to-end flow illustrates how the Redis coordination works:

Start Extension: The VS Code extension starts (e.g., via F5 in the debugger or opening VS Code).
Agent Initialization: The extension's activate function connects to Redis, ensures the agent_tasks stream and code_agents_group consumer group exist, and starts the agent's worker loop (startAgentWorker). This agent instance registers itself (conceptually) with a unique ID (agentInstanceId).
Indexing (Optional Initial Step): A user or an automated process triggers the thefuse.indexWorkspace command. This calls the CodeIndexer.indexWorkspace method, which reads codebase files, chunks them, gets embeddings, and stores them as Redis Hashes, indexed by RediSearch.
Task Enqueueing: A user runs thefuse.enqueueTask or another agent identifies work (e.g., a failed test triggers a debug task). This calls registerAndEnqueueNewTask, which:
Generates a unique taskId.
Stores the task details in the agent:tasks:registry Hash with status 'pending'.
Adds a message representing this task to the agent_tasks stream using XADD, including the taskId and target group (code_agents_group).
Task Consumption: The agent worker loop in one of the running extension instances (Consumers in the code_agents_group) reads the new message from the agent_tasks stream using XREADGROUP >.
Claim & Process: The agent receives the message, extracts the taskId, and immediately updates the task status in the agent:tasks:registry to 'assigned', including its agentInstanceId. It then attempts to acquireFileLock for the task's filePath.
Lock Acquired: If the lock is acquired, the agent updates the task status to 'in-progress'. It then performs the core task logic:
Reads file content using vscode.workspace.fs.readFile.
(Optional) Uses codeIndexer.searchSemantic to get relevant code context via RediSearch RAG.
Uses its LLM or other logic to generate changes.
Applies changes using vscode.workspace.applyEdit.
Completion/Failure:
If successful, the agent updates the task status in the registry to 'completed' and acknowledges the stream message using XACK.
If an error occurs, the agent catches it, updates the task status to 'failed' (including error message), and decides whether to acknowledge the message (and potentially move to DLQ) or leave it in the pending state for XAUTOCLAIM.
Lock Release: Regardless of success or failure, the agent always attempts to releaseFileLock in a finally block to free up the resource.
Pending Message Recovery: If an agent instance crashes mid-processing, its assigned messages in the stream's pending entries list (PEL) remain unacknowledged. The XAUTOCLAIM call within the consumption loop of other active agents will periodically find these messages (after minIdleTime), claim them, and re-queue them for processing by a healthy agent instance.
Monitoring: You can inspect the agent:tasks:registry Hash, the agent_tasks stream info (XINFO STREAM agent_tasks), and the consumer group info (XINFO GROUP agent_tasks code_agents_group) using Redis CLI or a GUI tool to monitor the state of tasks and agent activity.
5. Best Practices
Implementing robust A2A communication requires adhering to best practices:

Validate Message Formats: Always validate incoming messages against the defined structure and type-specific schemas.
Use Appropriate Channels/Streams: Publish messages to the most relevant stream (e.g., task-specific, event-specific, agent-specific) for efficient routing and consumption.
Set and Respect Priority: Use a priority field in messages and implement logic for agents to prioritize tasks.
Include Necessary Metadata: Include timestamp, source, target, taskId, and other context in message metadata for traceability and debugging.
Implement Robust Error Handling: Catch errors during message processing, log details, update task status, and use mechanisms like Dead Letter Queues (DLQ) for messages that consistently fail.
Use Atomic Operations: Leverage Redis transactions (MULTI/EXEC) or Lua scripts for operations that require atomicity (e.g., safe lock release).
Handle Large Payloads: Avoid putting very large data directly in stream messages or Hash fields. Store large content (like code files, analysis results) in separate Redis keys (e.g., Strings or larger Hashes/JSON documents) and pass references (keys) in the message payload.
Monitor System Health: Implement monitoring for Redis (connection health, memory usage, stream backlog, PEL size), agent processes, and task status in the registry.
Use Connection Pooling/Management: In a production environment, manage Redis connections efficiently using pooling or a dedicated client instance per component/service. Ensure proper connection shutdown.
Authenticate Agents: Implement authentication for agents connecting to Redis and potentially for MCP server interactions.
Encrypt Sensitive Data: Encrypt sensitive information transmitted in messages or stored in Redis if required.
Handle Agent Crashes: Design agents and use Redis Streams/XAUTOCLAIM to gracefully handle agent process crashes and ensure tasks are not lost.
5.1 Advanced Collaboration Patterns
Leverage the infrastructure for more sophisticated interactions:

Cascade Review Process: An agent completing a task enqueues a new task for a different agent specializing in review (e.g., security review, performance review).
Parallel Processing: An orchestrator agent breaks down a large task into smaller subtasks, enqueues them, and aggregates results from multiple agents processing in parallel.
Consensus Building: Agents working on a problem publish their findings/proposals to a stream. A coordinator agent collects responses and applies a consensus algorithm (e.g., voting, weighted confidence).
Hierarchical Task Delegation: A high-level agent receives a complex request and delegates subtasks to specialized agents based on their declared capabilities, tracking dependencies in the task registry.
5.2 Protocol Extensions
The message protocols should be designed for evolution:

Implement adaptive message formats that can evolve as requirements change. Use a version field in the message header.
Support for rich message formats including code snippets, images (as references to storage), and structured data using JSON or other serialization formats.
Develop standardized error codes and recovery procedures documented in the guide.
6. Testing & Integration
Rigorous testing is crucial for distributed systems.

Use provided VS Code tasks to initialize, test, and interact with MCP and agents.
Develop unit and integration tests for Redis interaction logic (messaging, locking, registry, search).
Create end-to-end test scenarios that simulate multiple agents processing tasks concurrently, including failure injection (e.g., killing an agent process to test XAUTOCLAIM).
Use logging and monitoring tools to trace message flow and agent activity.
7. Recommendations & Next Steps
This guide provides the blueprint. Next steps include:

Implement Core Services: Fully implement the A2ACoordinator, CodeIndexer, TaskHandler, and agent worker loop services/classes.
Refine Message Payloads: Define specific JSON schemas for the content field for each type of message (e.g., schema for COLLABORATION_REQUEST content, schema for TASK_UPDATE content).
Build Agent Logic: Develop the actual AI/LLM logic within agents that consumes tasks, uses RediSearch for RAG, interacts with VS Code, and produces results.
Develop UI Integration: Build the VS Code UI components (commands, views, notifications) that interact with the agent framework (e.g., enqueuing tasks, displaying task status, showing agent output).
Implement Robust Error Handling: Add comprehensive error handling, retry policies, and DLQ management based on the best practices.
Explore HNSW for Vector Index: Evaluate switching from FLAT to HNSW algorithm for RediSearch vector index if dataset size grows significantly for better performance and recall.
Document Findings: Continuously update this guide with implementation details, lessons learned, performance metrics, and new best practices.
8. Further Exploration
Dive deeper into related concepts and technologies:

Review all related markdown and JSON files in The New Fuse project for additional context.
Explore the MCP server and agent registration flows in detail.
Test agent-to-agent messaging and coordination in both local development and containerized deployment environments.
Investigate advanced features like capability discovery, dynamic task routing based on agent load/capabilities, and agent ranking/reputation systems.
8.1 Model Context Protocol (MCP) Integration
The Model Context Protocol provides a standardized way for LLMs to interact with tools and services. Agents can expose their capabilities as MCP tools.

Use the MCP framework to define standard tool interfaces that all agents can access.
Register agent capabilities as MCP tools that other agents can discover and invoke via the MCP server.
Leverage MCP for structured input/output validation across agent boundaries, improving reliability.
Explore the MCP server's role in facilitating agent discovery and capability matching based on declared profiles.
8.2 VSCode Extension Integration
The New Fuse VSCode extension provides the user interface and workspace access layer for the agents.

Agents running within the extension use the vscode API to interact with the user's workspace, files, and UI.
The extension defines various operational modes (Orchestrator, Debug, Ask, Architect, Code). These modes dictate the types of tasks enqueued, the agents involved, and the expected communication patterns.
9. Mode-Based Communication Protocols
The New Fuse adapts its communication patterns and agent interactions based on the current operational mode of the VS Code extension. These mode-specific protocols enable specialized and efficient agent collaboration tailored to the user's current task.

9.1 Mode-Specific Message Templates
Each mode utilizes specific message formats (building upon the Standard Message Structure) to optimize for its purpose. These are often used in the content payload of a message sent via Redis Streams.

Orchestrator Mode Messages
Used by orchestrator agents to direct the workflow of other agents.

JSON

{
    "type": "ORCHESTRATION_DIRECTIVE",
    "source": "orchestrator_agent_id",
    "targets": ["agent_alpha_id", "agent_beta_id"], // List of target agent IDs or group IDs
    "content": { // Payload specific to ORCHESTRATION_DIRECTIVE
        "task_id": "complex_refactor_123", // The overall complex task being orchestrated
        "directive_type": "execute_parallel_subtasks", // e.g., 'execute_sequential', 'aggregate_results'
        "subtasks": [
             { "task_id": "refactor_part_a", "agent_group": "refactor_agents", "dependencies": [] },
             { "task_id": "test_part_b", "agent_group": "test_agents", "dependencies": ["refactor_part_a"] }
        ],
        "priority": "high",
        "workflow": "parallel_with_checkpoints", // High-level workflow description
        "success_criteria": ["all_tests_pass", "performance_improvement_20_percent"],
        "context_data": { /* Shared context or data needed by subtasks */ }
    },
    "timestamp": "2024-04-27T15:45:00Z"
    // Standard message fields like message_id handled by Redis
}
Debug Mode Messages
Used by debug agents to coordinate analysis of issues.

JSON

{
    "type": "DEBUG_REQUEST",
    "source": "debug_coordinator_id",
    "target": "specialized_debug_agent_id",
    "content": { // Payload specific to DEBUG_REQUEST
        "debug_session_id": "session_abc", // Link to a debug session
        "error_trace": "<stack_trace_data>", // Detailed error information
        "reproduction_steps": ["step1", "step2", "step3"],
        "affected_components": ["component_a", "component_b"],
        "priority": "critical",
        "analysis_request": {
            "method": "systematic_trace", // Analysis technique
            "depth": "comprehensive",
            "focus_areas": ["memory_management", "race_conditions"]
        },
        "context_snapshot": { /* References to logs, variable states, etc. */ }
    },
    "timestamp": "2024-04-27T16:10:00Z"
}
Ask Mode Messages
Used for direct user queries routed to appropriate agents.

JSON

{
    "type": "INFORMATION_REQUEST",
    "source": "user_proxy_agent_id", // Agent representing the user
    "target": "knowledge_agent_id", // Agent specializing in knowledge retrieval
    "content": { // Payload specific to INFORMATION_REQUEST
        "query_id": "query_456", // Unique ID for this query session
        "question": "How does the MCP protocol enhance agent communication?",
        "context": {
            "user_knowledge_level": "intermediate",
            "relevant_domains": ["distributed_systems", "ai_engineering"],
            "current_document": "guide.md" // Context from user's environment
        },
        "response_format": "markdown", // Desired output format
        "max_length": "comprehensive" // Desired level of detail
    },
    "timestamp": "2024-04-27T16:15:00Z"
}
Architect Mode Messages
Used for collaborative system design and planning tasks.

JSON

{
    "type": "ARCHITECTURE_PROPOSAL", // Or ARCHITECTURE_REVIEW_REQUEST, ARCHITECTURE_FEEDBACK
    "source": "architect_agent_id",
    "target": "implementation_team_group_id", // Target group for review/feedback
    "content": { // Payload specific to ARCHITECTURE_PROPOSAL
        "design_id": "arch_v1.2", // Unique ID for the design iteration
        "system_name": "Agent Communication Framework",
        "components": [
            {
                "name": "message_broker",
                "responsibilities": ["routing", "queuing", "delivery_confirmation"],
                "technologies": ["Redis", "RabbitMQ"]
            },
            {
                "name": "protocol_adapter",
                "responsibilities": ["format_translation", "version_compatibility"],
                "technologies": ["JSON Schema", "Protocol Buffers"]
            }
        ],
        "data_flows": ["client_to_broker", "broker_to_agent", "agent_to_agent"],
        "security_considerations": ["message_encryption", "agent_authentication"],
        "diagram_url": "url_to_shared_diagram" // Link to visual representation
    },
    "implementation_phases": ["research", "prototype", "testing", "deployment"],
    "timestamp": "2024-04-27T16:30:00Z"
}
Code Mode Messages
Used for agents collaborating directly on code-related tasks like refactoring, code generation, or review.

JSON

{
    "type": "CODE_COLLABORATION",
    "source": "code_agent_primary_id",
    "target": "code_agent_secondary_id", // Specific agent or group
    "content": { // Payload specific to CODE_COLLABORATION
        "collaboration_id": "code_review_456", // Unique ID for this collaboration instance
        "task": { // Details of the code task
            "action": "code_review", // e.g., 'code_review', 'generate_code', 'apply_patch'
            "files": ["src/services/A2ACoordinator.ts", "src/mcp/SimpleMCPServer.js"], // Files involved
            "focus": ["error_handling", "performance_optimization", "security"], // Areas to focus on
            "standards": ["OWASP_TOP_10", "TypeScript_Best_Practices"],
            "diff": "<patch_format>" // Optional: Include proposed changes directly if small
        },
        "context": { // Relevant project/task context
            "project_stage": "beta",
            "priority": "high",
            "deadline": "2024-04-30T00:00:00Z",
             "relevant_code_refs": [{ "file": "...", "lines": "..." }] // References found via RediSearch
        },
        "request_format": "inline_comments" // Desired format for review feedback
    },
    "timestamp": "2024-04-27T16:45:00Z"
}
9.2 Mode Transition Protocol
When the user switches modes in the VS Code extension, the agent framework uses a standardized transition protocol to inform relevant agents, allowing them to adjust their behavior, load/unload mode-specific context, and synchronize state.

JSON

{
    "type": "MODE_TRANSITION",
    "source": "transition_coordinator_id", // Or the user proxy agent
    "target": "all_agents_group_id", // Broadcast to all agents
    "content": { // Payload specific to MODE_TRANSITION
        "transition_id": "trans_789", // Unique ID for this transition event
        "from_mode": "debug",
        "to_mode": "architect",
        "reason": "debug_complete_moving_to_redesign",
        "context_preservation": { // Instructions on handling mode-specific state
            "preserve_variables": ["error_root_cause", "affected_modules"],
            "reset_variables": ["debug_steps", "reproduction_case"]
        }
    },
    "synchronization": { // Optional: details for agents needing to synchronize
        "method": "barrier", // e.g., 'barrier' (wait for all), 'eventual'
        "timeout_seconds": 30,
        "fallback": "force_transition" // What to do if sync fails
    },
    "timestamp": "2024-04-27T17:00:00Z"
}
9.3 Mode-Specific Tool Access
Different modes grant agents access to different tools and capabilities, often managed or enforced by the MCP server or a central policy agent. Agents must respect these restrictions.

Mode	Read Access (Codebase)	Write Access (Codebase)	Terminal Commands	Browser Control	MCP Tools Available
Orchestrator	Full	Full	Full	Full	Full
Debug	Full	Limited (Diagnostics)	Read-only	Limited	Diagnostics, Logging
Ask	Full	None	None	Limited	Query-only, Knowledge
Architect	Full	Markdown/Diagrams only	None	Full	Design tools
Code	Full	Full	Development tools	Limited	Development tools

Export to Sheets
Agents should receive policy updates (potentially via a dedicated stream) indicating the allowed tools and access levels for the current mode.

10. Agent Specialization & Personalization
Agents within The New Fuse ecosystem can define specialized roles and capabilities, and declare communication preferences to facilitate more effective and tailored collaboration.

10.1 Role Definition Protocol
Agents declare their specific role and associated capabilities beyond their primary function. This information can be stored in a shared registry (e.g., Redis Hash or RediSearch index for searchable profiles).

JSON

{
    "type": "ROLE_DEFINITION",
    "source": "security_auditor_agent_id", // Agent declaring the role
    "content": { // Payload specific to ROLE_DEFINITION
        "specialization": "security_auditor", // Defined role identifier
        "description": "Specializes in identifying security vulnerabilities and suggesting fixes.",
        "capabilities": [ // Specific capabilities related to this role
            {
                "id": "vulnerability_scanning",
                "proficiency": 0.95, // Self-assessed proficiency in this capability
                "tools": ["static_analysis", "dependency_check", "owasp_zap"] // Tools used by this capability
            },
            {
                "id": "security_review",
                "proficiency": 0.87,
                "tools": ["code_review_guidelines", "threat_modeling_frameworks"]
            }
        ],
        "work_preferences": { // How this agent prefers to receive tasks or collaborate
            "detail_level": "high", // e.g., 'high', 'medium', 'low'
            "collaboration_style": "advisory", // e.g., 'advisory', 'autonomous', 'pair_programming'
            "communication_frequency": "checkpoints_only" // e.g., 'realtime', 'checkpoints_only', 'daily_summary'
        }
    },
    "timestamp": "2024-04-27T17:15:00Z"
}
10.2 Adaptive Communication Patterns
Agents should be designed to adapt their communication style (verbosity, technical depth, format) based on the declared preferences of the recipient agent or group, leading to more efficient and less frustrating interactions. This information can be stored and retrieved from a shared registry.

JSON

{
    "type": "COMMUNICATION_PREFERENCE_REGISTRY", // Message type used by a registry service to publish updates
    "source": "registry_service_id",
    "target": "all_agents_group_id", // Broadcast updates to all agents
    "content": { // Payload specific to COMMUNICATION_PREFERENCE_REGISTRY
        "update_type": "full_sync", // Or 'delta_update'
        "entries": [ // List of agents and their preferences
            {
                "agent_id": "detailed_planner_id",
                "preferences": {
                    "verbosity": "high",
                    "format": "structured", // e.g., 'structured', 'narrative', 'code_only'
                    "technical_depth": "expert", // e.g., 'high', 'implementation_focused', 'conceptual'
                    "examples_needed": true,
                    "visualization_preferred": true
                }
            },
            {
                "agent_id": "rapid_implementer_id",
                "preferences": {
                    "verbosity": "low",
                    "format": "concise",
                    "technical_depth": "implementation_focused",
                    "examples_needed": true,
                    "visualization_preferred": false
                }
            }
            // ... entries for all known agents
        ]
    },
    "timestamp": "2024-04-27T17:30:00Z"
}
Agents would consume messages of type COMMUNICATION_PREFERENCE_REGISTRY from a broadcast stream to maintain a local cache of other agents' preferences or query the registry directly.

11. MCP Integration Best Practices
Leveraging the Model Context Protocol (MCP) provides a standardized way for agents (especially those backed by LLMs) to interact with tools and capabilities provided by other agents.

11.1 MCP Server Registration
Agents providing capabilities as MCP tools should register these tools with the central MCP server upon startup or capability change.

JSON

{
    "type": "MCP_SERVER_REGISTRATION", // Message type for registering with MCP server
    "source": "tool_provider_agent_id",
    "target": "mcp_server_id",
    "content": { // Payload specific to MCP_SERVER_REGISTRATION
        "agent_id": "tool_provider_agent_id",
        "server_details": { // Details about where the agent's MCP endpoint can be reached
            "endpoint": "http://tool_provider_agent_host:port/mcp", // Endpoint URL
            "protocol_version": "1.0",
            "transport": "http_json_rpc", // e.g., 'http_json_rpc', 'websocket_json'
            "authentication": { // How the MCP server/other agents should authenticate
                "method": "bearer_token",
                "token_location": "header" // Or 'query_param', etc.
            }
        },
        "provided_tools": [ // List of tools the agent exposes via MCP
            {
                "name": "code_analyzer", // Unique tool name
                "description": "Analyzes code for quality, complexity, and patterns.",
                "parameters": { // JSON Schema or simple type definition for input parameters
                    "code": "string",
                    "language": "string",
                    "analysis_type": { "type": "string", "enum": ["complexity", "quality", "security"] }
                },
                "returns": "object", // Expected return type
                "requires_lock": false, // Does this tool require a file lock?
                "estimated_cost": { "unit": "compute_seconds", "value": 0.5 } // Cost estimate for invoking
            }
            // ... other tools
        ]
    },
    "timestamp": "2024-04-27T17:45:00Z"
}
11.2 MCP Tool Invocation
Agents needing to use a capability provided by another agent send a message (potentially via a stream or directly if using a request/response pattern over a temporary channel) containing the tool invocation request. This might be facilitated by the MCP server routing the request.

JSON

{
    "type": "MCP_TOOL_INVOCATION", // Message type for requesting tool execution
    "source": "requester_agent_id",
    "target": "tool_provider_agent_id", // Target the specific agent instance or a group that provides the tool
    "content": { // Payload specific to MCP_TOOL_INVOCATION
        "tool": "code_analyzer", // Name of the tool to invoke
        "parameters": { // Parameters for the tool call, matching the tool's definition
            "code": "function example() { return 'test'; }",
            "language": "javascript",
            "analysis_type": "complexity"
        },
        "request_id": "req_12345", // Unique ID for this specific invocation request
        "timeout_ms": 5000, // Maximum time to wait for a response
        "callback_address": "agent:requester_agent_id:inbox" // Stream or channel for the response
    },
    "timestamp": "2024-04-27T18:00:00Z"
}
Note: In a system using Redis Streams as the primary bus, this message would likely be put on the agent:tool_provider_agent_id:inbox stream (if targeting a specific agent) or a tasks:mcp_invocation stream consumed by a pool of tool-invoking agents. The callback_address directs the response.

11.3 MCP Response Format
Agents processing an MCP_TOOL_INVOCATION message execute the tool and send a response message back to the callback_address specified in the request.

JSON

{
    "type": "MCP_TOOL_RESPONSE", // Message type for the tool execution result
    "source": "tool_provider_agent_id",
    "target": "requester_agent_id", // Target the requesting agent
    "content": { // Payload specific to MCP_TOOL_RESPONSE
        "request_id": "req_12345", // Matching ID from the invocation request
        "status": "success", // 'success' or 'failure'
        "result": { // The output of the tool execution if status is 'success'
            "complexity": {
                "cyclomatic": 1,
                "cognitive": 1
            },
            "quality_score": 0.95,
            "suggestions": [
                "Add function documentation"
            ]
        },
        "error": { // Details if status is 'failure'
            "code": "TOOL_EXECUTION_ERROR",
            "message": "Analysis failed due to invalid input."
        },
        "performance": { // Optional performance metrics
            "execution_time_ms": 124,
            "resource_usage": "minimal"
        }
    },
    "timestamp": "2024-04-27T18:00:10Z"
}
This guide is a living document. All agents and contributors are encouraged to keep it up to date as the system grows and improves by adding new sections, refining existing ones, and proposing changes based on implementation and operational experience.